{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KoELECTRA_hyunho.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"120f1a4962704999bb4b831d42e5b244":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fae9fb86cf2c40dda290668b64f382fc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eace7dcb662348a0984338bc0d05bbf6","IPY_MODEL_a20dd6e556104c87ba29c594ec36330f","IPY_MODEL_847a751d3bb94e55b2f5a4ce5abc8828"]}},"fae9fb86cf2c40dda290668b64f382fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eace7dcb662348a0984338bc0d05bbf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e35e26645da4c129f14bbd298205fe0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76341662e98449f7ae21163c49391660"}},"a20dd6e556104c87ba29c594ec36330f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d7816117de0d462cb48eabb5230210df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":467,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7724c613d3b94b34872e044d38cc8efa"}},"847a751d3bb94e55b2f5a4ce5abc8828":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3f045c2d0e8549179a2a3d78bdad9cab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467/467 [00:00&lt;00:00, 2.68kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d3f75043b3b45cbb2ff974f85990447"}},"7e35e26645da4c129f14bbd298205fe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"76341662e98449f7ae21163c49391660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7816117de0d462cb48eabb5230210df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7724c613d3b94b34872e044d38cc8efa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f045c2d0e8549179a2a3d78bdad9cab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0d3f75043b3b45cbb2ff974f85990447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c95cd548fc94af996fcf8503cbe9ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ad409c8dd9e04252b0c9bc4601cc4fd1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c6d53a2b6394a2682e4a6748607ef58","IPY_MODEL_36c3521b3caa47ee951fed51c7f69318","IPY_MODEL_bf55ea51942e4509a683449ed621d57b"]}},"ad409c8dd9e04252b0c9bc4601cc4fd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c6d53a2b6394a2682e4a6748607ef58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cce9dd24f4e94af88a00bbcd5252c487","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81dab11fc5ff457c95798ae0d4c042a7"}},"36c3521b3caa47ee951fed51c7f69318":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0a551da398a941bd9d01ed3917d18668","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":451741507,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":451741507,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53524edcd4894286825d95be5932d951"}},"bf55ea51942e4509a683449ed621d57b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9837659f6a414fc9bb258aeabe460ffe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 431M/431M [00:16&lt;00:00, 37.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cde90de7ad5456fb0ac099c1ffc38f0"}},"cce9dd24f4e94af88a00bbcd5252c487":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81dab11fc5ff457c95798ae0d4c042a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a551da398a941bd9d01ed3917d18668":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"53524edcd4894286825d95be5932d951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9837659f6a414fc9bb258aeabe460ffe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0cde90de7ad5456fb0ac099c1ffc38f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a35bb858323c440180290440bfd39340":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2ed6e4a649a54a84ac362e5c719357c4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ccdfdfee2e774932825dcd9c77a44fc1","IPY_MODEL_1ebe30016a044a6199c5cf0307b12465","IPY_MODEL_0004d3a784834673a1b7cecd87f7164d"]}},"2ed6e4a649a54a84ac362e5c719357c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ccdfdfee2e774932825dcd9c77a44fc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7362b4657747493893b2d7ac88a7fffb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd3d6acfaa23462194805c22445ffe6f"}},"1ebe30016a044a6199c5cf0307b12465":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8682454d875e44efb924a4bc44669bc2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":61,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":61,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bce444660bd64879a740ce829912c3e7"}},"0004d3a784834673a1b7cecd87f7164d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cccc52ff3ce4e9b815466dacfae9ed5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 61.0/61.0 [00:00&lt;00:00, 1.52kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5ec1d5f827542ff9d63fe5a733598c2"}},"7362b4657747493893b2d7ac88a7fffb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd3d6acfaa23462194805c22445ffe6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8682454d875e44efb924a4bc44669bc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bce444660bd64879a740ce829912c3e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6cccc52ff3ce4e9b815466dacfae9ed5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d5ec1d5f827542ff9d63fe5a733598c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fb90631f8914a998bd6596469ca0518":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dfd5c25d10484ca9a78493ed9dfe88cf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b954030fae2439496b5bdace8ad91ee","IPY_MODEL_a93c853d8c9b408b88b7d9c90ff574a6","IPY_MODEL_1f446088b1c34caab18e95dce3d3374e"]}},"dfd5c25d10484ca9a78493ed9dfe88cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b954030fae2439496b5bdace8ad91ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6e7f04e7f1714455abe5d7415eda6b96","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18ec5da951094214a9e7ee9033f25d48"}},"a93c853d8c9b408b88b7d9c90ff574a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_28434517587742c48120ccd63c970d1f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":263326,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":263326,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4ae949de7754e5ca66cdad839531589"}},"1f446088b1c34caab18e95dce3d3374e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dad8ffbaad6f41dd9941486702bd8ab0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 257k/257k [00:00&lt;00:00, 1.14MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88c1127744c248efb86ced029da53a5b"}},"6e7f04e7f1714455abe5d7415eda6b96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"18ec5da951094214a9e7ee9033f25d48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28434517587742c48120ccd63c970d1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e4ae949de7754e5ca66cdad839531589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dad8ffbaad6f41dd9941486702bd8ab0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"88c1127744c248efb86ced029da53a5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# 설정, 설치 임포트"],"metadata":{"id":"2Gdm7kFeAxq8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bbkvzkru6NE","executionInfo":{"status":"ok","timestamp":1644580803096,"user_tz":-540,"elapsed":83401,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02238787557942782369"}},"outputId":"44ed2e2a-373a-4bbc-a5df-652c81de0790"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/015GithubRepos/Dacon_sentence_classification')"],"metadata":{"id":"lHrIc-pcu7px","executionInfo":{"status":"ok","timestamp":1644580803697,"user_tz":-540,"elapsed":607,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02238787557942782369"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RSyNx8K2N3M","executionInfo":{"status":"ok","timestamp":1644580825888,"user_tz":-540,"elapsed":10029,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02238787557942782369"}},"outputId":"3ebeb9c7-9f19-4e13-dbb8-b652a6e3fa2d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 26.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 39.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"]}]},{"cell_type":"code","source":["import pandas as pd \n","import numpy as np \n","import os\n","import torch\n","import torch.nn as nn\n","\n","import warnings \n","warnings.filterwarnings(\"ignore\")\n","from tqdm import tqdm\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","import re\n","from sklearn.model_selection import train_test_split\n","#%% Seed Fix\n","\n","import random\n","def seed_everything(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  \n","    torch.backends.cudnn.deterministic = True  \n","    torch.backends.cudnn.benchmark = True  \n","seed_everything()\n","\n","#%%\n","\n","device = torch.device(\"cuda\")\n","\n","# local = 'C:/Users/posick/Desktop/Dacon/open/'\n","# local2 = 'C:/Users/201/Desktop/Dacon/'\n","suv = 'data/'\n","# colab = '/content/drive/MyDrive/Dacon/'\n","\n","#%% \n","num_epochs = 10\n","batch_size =128\n","lr = 0.00001\n","pretrain = \"monologg/koelectra-base-v3-discriminator\"\n","\n","#%% data load \n","\n","def load_data(path):\n","    train = pd.read_csv(path+'train_data.csv')\n","    label_dict = {\"entailment\" : 0, \"contradiction\" : 1, \"neutral\" : 2}\n","    train['label'] = train['label'].map(label_dict)\n","    test = pd.read_csv(path+'test_data.csv')\n","    sample_submission = pd.read_csv(path+'sample_submission.csv')\n","    \n","    return train,test,sample_submission \n","\n","def text_clean(df):\n","    df[\"premise_\"] = \"[CLS]\" + df[\"premise\"] + \"[SEP]\"\n","    df[\"hypothesis_\"] = df[\"hypothesis\"] + \"[SEP]\"\n","    df[\"text_sum\"] = df.premise_ + \" \" + df.hypothesis_\n","    df = df[['text_sum','label']]\n","    return df \n","\n","train,test,sample_submission = load_data(suv)\n","clean_train,clean_test  = text_clean(train),text_clean(test)\n","\n","\n","#%%data loader \n","\n","class CustomDataset(Dataset):\n","  \n","  def __init__(self,dataset,option):\n","    \n","    self.dataset = dataset \n","    self.option = option\n","    self.tokenizer = AutoTokenizer.from_pretrained(pretrain)\n","\n","  \n","  def __len__(self):\n","    return len(self.dataset)\n","  \n","  def __getitem__(self, idx):\n","    row = self.dataset.iloc[idx, 0:2].values\n","    text = row[0]\n","    #y = row[1]\n","\n","    inputs = self.tokenizer(\n","        text, \n","        return_tensors='pt',\n","        truncation=True,\n","        max_length=70,\n","        pad_to_max_length=True,\n","        add_special_tokens=False\n","        )\n","    \n","    input_ids = inputs['input_ids'][0]\n","    attention_mask = inputs['attention_mask'][0]\n","    \n","    if self.option =='train':\n","        y =row[1]\n","        return input_ids,attention_mask,y\n","\n","    return input_ids, attention_mask\n","\n","\n","#%% Cross validation \n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","skf = StratifiedKFold(n_splits = 5,shuffle=True,random_state=42)\n","folds=[]\n","for trn_idx,val_idx in skf.split(clean_train['text_sum'],clean_train['label']):\n","    folds.append((trn_idx,val_idx))\n","    \n","    \n","#%%\n","#model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\",num_labels=3).to(device)\n","#%%\n","#model\n","\n","#n=0\n","#for name, child in model.named_children():\n","#    if n==0:\n","#      h=0\n","#      for param in child.parameters():\n","#        if h<=328: #이부분 숫자 조절로 fine-tuning => Roberta229: h=229\n","#          param.requires_grad = False\n","#        h+=1\n","#    n+=1\n","    "],"metadata":{"id":"WvfFd1xyAvwz","executionInfo":{"status":"ok","timestamp":1644580846331,"user_tz":-540,"elapsed":15557,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02238787557942782369"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["best_models = []\n","\n","for i,fold in enumerate(range(5)):\n","    print('===============',i+1,'fold start===============')\n","    model = ElectraForSequenceClassification.from_pretrained(pretrain,num_labels=3).to(device)\n","    model=nn.DataParallel(model).to(device)\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","    \n","    \n","    train_idx = folds[fold][0]\n","    valid_idx = folds[fold][1]\n","    train_data = clean_train.loc[trn_idx]\n","    val_data = clean_train.loc[valid_idx]\n","    train_dataset = CustomDataset(train_data,'train')\n","    valid_dataset = CustomDataset(val_data,'train')\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","    warmup_ratio = 0.1\n","    total_steps = len(train_loader) * num_epochs\n","    warmup_step = int(total_steps * warmup_ratio)\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=total_steps)\n","    valid_loss_min = 0.4\n","    valid_acc_max = 0.8\n","    \n","    for epoch in range(num_epochs):\n","        batches = 0\n","        total_loss = 0.0\n","        correct = 0\n","        total =0\n","        model.train()\n","        \n","        for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n","            optimizer.zero_grad()\n","            y_batch = y_batch.to(device)\n","            y_pred = model(input_ids_batch.to(device), attention_mask = attention_masks_batch.to(device))[0]\n","            loss = F.cross_entropy(y_pred, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","            _, predicted = torch.max(y_pred, 1)\n","            correct += (predicted == y_batch).sum()\n","            total += len(y_batch)\n","            batches += 1\n","            if batches % 100 == 0:\n","                print(\"Batch Loss: \", total_loss, \"Accuracy: \", correct.float() / total)\n","      \n","        val_loss = []\n","        val_acc = []\n","        \n","        for input_ids_batch, attention_masks_batch, y_batch in tqdm(valid_loader):\n","            \n","            model.eval()\n","            with torch.no_grad():\n","                \n","                y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n","                valid_loss = F.cross_entropy(y_pred,y_batch.to(device)).cpu().detach().numpy()\n","\n","                preds = torch.argmax(y_pred,1)\n","                preds = preds.cpu().detach().numpy()\n","                y_batch = y_batch.cpu().detach().numpy()\n","                batch_acc = (preds==y_batch).mean()\n","                val_loss.append(valid_loss)\n","                val_acc.append(batch_acc)\n","                \n","                \n","        val_loss = np.mean(val_loss)\n","        val_acc = np.mean(val_acc)\n","        scheduler.step()\n","        print(f'Epoch: {epoch} - valid Loss: {val_loss:.6f} - valid_acc : {val_acc:.6f}')\n","        print(optimizer.param_groups[0][\"lr\"])\n","        if valid_acc_max < val_acc:\n","            valid_acc_max = val_acc\n","            best_models.append(model)\n","            print('model save, model val acc : ',val_acc)\n","            print('best_models size : ',len(best_models))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["120f1a4962704999bb4b831d42e5b244","fae9fb86cf2c40dda290668b64f382fc","eace7dcb662348a0984338bc0d05bbf6","a20dd6e556104c87ba29c594ec36330f","847a751d3bb94e55b2f5a4ce5abc8828","7e35e26645da4c129f14bbd298205fe0","76341662e98449f7ae21163c49391660","d7816117de0d462cb48eabb5230210df","7724c613d3b94b34872e044d38cc8efa","3f045c2d0e8549179a2a3d78bdad9cab","0d3f75043b3b45cbb2ff974f85990447","0c95cd548fc94af996fcf8503cbe9ec4","ad409c8dd9e04252b0c9bc4601cc4fd1","4c6d53a2b6394a2682e4a6748607ef58","36c3521b3caa47ee951fed51c7f69318","bf55ea51942e4509a683449ed621d57b","cce9dd24f4e94af88a00bbcd5252c487","81dab11fc5ff457c95798ae0d4c042a7","0a551da398a941bd9d01ed3917d18668","53524edcd4894286825d95be5932d951","9837659f6a414fc9bb258aeabe460ffe","0cde90de7ad5456fb0ac099c1ffc38f0","a35bb858323c440180290440bfd39340","2ed6e4a649a54a84ac362e5c719357c4","ccdfdfee2e774932825dcd9c77a44fc1","1ebe30016a044a6199c5cf0307b12465","0004d3a784834673a1b7cecd87f7164d","7362b4657747493893b2d7ac88a7fffb","fd3d6acfaa23462194805c22445ffe6f","8682454d875e44efb924a4bc44669bc2","bce444660bd64879a740ce829912c3e7","6cccc52ff3ce4e9b815466dacfae9ed5","d5ec1d5f827542ff9d63fe5a733598c2","9fb90631f8914a998bd6596469ca0518","dfd5c25d10484ca9a78493ed9dfe88cf","7b954030fae2439496b5bdace8ad91ee","a93c853d8c9b408b88b7d9c90ff574a6","1f446088b1c34caab18e95dce3d3374e","6e7f04e7f1714455abe5d7415eda6b96","18ec5da951094214a9e7ee9033f25d48","28434517587742c48120ccd63c970d1f","e4ae949de7754e5ca66cdad839531589","dad8ffbaad6f41dd9941486702bd8ab0","88c1127744c248efb86ced029da53a5b"]},"id":"LMZBmRj8Avuo","executionInfo":{"status":"error","timestamp":1644595544789,"user_tz":-540,"elapsed":14698479,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02238787557942782369"}},"outputId":"c6ce99db-7392-4615-b664-f1a2a7fd287c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["=============== 1 fold start===============\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"120f1a4962704999bb4b831d42e5b244","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c95cd548fc94af996fcf8503cbe9ec4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/431M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a35bb858323c440180290440bfd39340","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fb90631f8914a998bd6596469ca0518","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/257k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:44<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  109.72513401508331 Accuracy:  tensor(0.3592, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:23<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0 - valid Loss: 1.095447 - valid_acc : 0.391797\n","1e-05\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  84.93394750356674 Accuracy:  tensor(0.6548, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1 - valid Loss: 0.375572 - valid_acc : 0.877344\n","9.999989977092514e-06\n","model save, model val acc :  0.87734375\n","best_models size :  1\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  38.87187622487545 Accuracy:  tensor(0.8676, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2 - valid Loss: 0.227332 - valid_acc : 0.928711\n","9.999959908410236e-06\n","model save, model val acc :  0.9287109375\n","best_models size :  2\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  28.896242022514343 Accuracy:  tensor(0.9054, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3 - valid Loss: 0.151015 - valid_acc : 0.955273\n","9.999909794073715e-06\n","model save, model val acc :  0.9552734375\n","best_models size :  3\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:40,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  21.035183809697628 Accuracy:  tensor(0.9318, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:21<00:00,  2.81s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4 - valid Loss: 0.103415 - valid_acc : 0.972266\n","9.99983963428387e-06\n","model save, model val acc :  0.972265625\n","best_models size :  4\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:43<02:41,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  16.350761868059635 Accuracy:  tensor(0.9497, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5 - valid Loss: 0.080190 - valid_acc : 0.979102\n","9.999749429321982e-06\n","model save, model val acc :  0.9791015625\n","best_models size :  5\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:43<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  13.364772409200668 Accuracy:  tensor(0.9600, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:23<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6 - valid Loss: 0.049668 - valid_acc : 0.988281\n","9.999639179549699e-06\n","model save, model val acc :  0.98828125\n","best_models size :  6\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:45<02:42,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  9.881972555071115 Accuracy:  tensor(0.9706, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:26<00:00,  2.85s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7 - valid Loss: 0.034038 - valid_acc : 0.992969\n","9.999508885409028e-06\n","model save, model val acc :  0.99296875\n","best_models size :  7\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:45<02:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  7.731785601004958 Accuracy:  tensor(0.9769, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8 - valid Loss: 0.025126 - valid_acc : 0.994336\n","9.999358547422342e-06\n","model save, model val acc :  0.9943359375\n","best_models size :  8\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:45<02:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  7.021880384534597 Accuracy:  tensor(0.9808, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:26<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9 - valid Loss: 0.020542 - valid_acc : 0.996289\n","9.999188166192368e-06\n","model save, model val acc :  0.9962890625\n","best_models size :  9\n","=============== 2 fold start===============\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 64%|██████▎   | 100/157 [04:45<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  109.83966147899628 Accuracy:  tensor(0.3388, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:26<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0 - valid Loss: 1.098895 - valid_acc : 0.317773\n","1e-05\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:46<02:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  91.56615382432938 Accuracy:  tensor(0.5885, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:27<00:00,  2.85s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1 - valid Loss: 0.387070 - valid_acc : 0.872461\n","9.999989977092514e-06\n","model save, model val acc :  0.8724609375\n","best_models size :  10\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:44<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  40.36764547228813 Accuracy:  tensor(0.8585, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2 - valid Loss: 0.244025 - valid_acc : 0.923633\n","9.999959908410236e-06\n","model save, model val acc :  0.9236328125\n","best_models size :  11\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:43<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  27.737796157598495 Accuracy:  tensor(0.9063, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:23<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3 - valid Loss: 0.166544 - valid_acc : 0.950781\n","9.999909794073715e-06\n","model save, model val acc :  0.95078125\n","best_models size :  12\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  19.715318977832794 Accuracy:  tensor(0.9373, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:21<00:00,  2.81s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4 - valid Loss: 0.117789 - valid_acc : 0.968164\n","9.99983963428387e-06\n","model save, model val acc :  0.9681640625\n","best_models size :  13\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:43<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  15.99383869022131 Accuracy:  tensor(0.9525, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5 - valid Loss: 0.082058 - valid_acc : 0.979688\n","9.999749429321982e-06\n","model save, model val acc :  0.9796875\n","best_models size :  14\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  11.793493317440152 Accuracy:  tensor(0.9656, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6 - valid Loss: 0.056030 - valid_acc : 0.986914\n","9.999639179549699e-06\n","model save, model val acc :  0.9869140625\n","best_models size :  15\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:43<02:41,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  9.298936219885945 Accuracy:  tensor(0.9734, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7 - valid Loss: 0.043384 - valid_acc : 0.989648\n","9.999508885409028e-06\n","model save, model val acc :  0.9896484375\n","best_models size :  16\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:43<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  7.848069893196225 Accuracy:  tensor(0.9764, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8 - valid Loss: 0.032630 - valid_acc : 0.992383\n","9.999358547422342e-06\n","model save, model val acc :  0.9923828125\n","best_models size :  17\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  5.9981485633179545 Accuracy:  tensor(0.9824, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9 - valid Loss: 0.023265 - valid_acc : 0.995313\n","9.999188166192368e-06\n","model save, model val acc :  0.9953125\n","best_models size :  18\n","=============== 3 fold start===============\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  110.14424085617065 Accuracy:  tensor(0.3241, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0 - valid Loss: 1.101079 - valid_acc : 0.320898\n","1e-05\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:45<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  88.23669734597206 Accuracy:  tensor(0.6259, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1 - valid Loss: 0.408190 - valid_acc : 0.865234\n","9.999989977092514e-06\n","model save, model val acc :  0.865234375\n","best_models size :  19\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:45<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  39.407834976911545 Accuracy:  tensor(0.8649, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2 - valid Loss: 0.248094 - valid_acc : 0.920898\n","9.999959908410236e-06\n","model save, model val acc :  0.9208984375\n","best_models size :  20\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:45<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  28.281151354312897 Accuracy:  tensor(0.9083, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3 - valid Loss: 0.172162 - valid_acc : 0.950195\n","9.999909794073715e-06\n","model save, model val acc :  0.9501953125\n","best_models size :  21\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:44<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  21.664254255592823 Accuracy:  tensor(0.9321, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4 - valid Loss: 0.123012 - valid_acc : 0.967773\n","9.99983963428387e-06\n","model save, model val acc :  0.9677734375\n","best_models size :  22\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:44<02:42,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  16.9687410145998 Accuracy:  tensor(0.9470, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5 - valid Loss: 0.089705 - valid_acc : 0.976367\n","9.999749429321982e-06\n","model save, model val acc :  0.9763671875\n","best_models size :  23\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:44<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  12.101420897990465 Accuracy:  tensor(0.9638, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:23<00:00,  2.83s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6 - valid Loss: 0.060783 - valid_acc : 0.985547\n","9.999639179549699e-06\n","model save, model val acc :  0.985546875\n","best_models size :  24\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  10.2985326834023 Accuracy:  tensor(0.9705, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7 - valid Loss: 0.044113 - valid_acc : 0.991211\n","9.999508885409028e-06\n","model save, model val acc :  0.9912109375\n","best_models size :  25\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:42<02:41,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  7.967084295116365 Accuracy:  tensor(0.9771, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:22<00:00,  2.82s/it]\n","100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8 - valid Loss: 0.031831 - valid_acc : 0.993164\n","9.999358547422342e-06\n","model save, model val acc :  0.9931640625\n","best_models size :  26\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▎   | 100/157 [04:44<02:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Batch Loss:  6.659367703832686 Accuracy:  tensor(0.9801, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [07:25<00:00,  2.84s/it]\n","100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9 - valid Loss: 0.027649 - valid_acc : 0.993359\n","9.999188166192368e-06\n","model save, model val acc :  0.993359375\n","best_models size :  27\n","=============== 4 fold start===============\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  1%|          | 1/157 [00:03<08:02,  3.09s/it]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a7ee9fe08e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_masks_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         )\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m                 )\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         )\n\u001b[1;32m    406\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 11.17 GiB total capacity; 10.15 GiB already allocated; 17.81 MiB free; 10.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["y_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FC5KoTEAvqm","executionInfo":{"status":"ok","timestamp":1644570349623,"user_tz":-540,"elapsed":275,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"fb8d3f96-2b78-4f17-d9f4-abc519a5df41"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["temp"],"metadata":{"id":"aGoUfPjlAvov","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1644595545055,"user_tz":-540,"elapsed":22,"user":{"displayName":"이경찬","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02238787557942782369"}},"outputId":"3cffb75a-8166-490d-a49e-3e332a01e228"},"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-da77557ed0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"]}]},{"cell_type":"code","source":["torch.load()"],"metadata":{"id":"YvTRdUEQAvma"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"1n8K2tXoAvkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ZOuxXPQiAviw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YNQxUIAlAvga"},"execution_count":null,"outputs":[]}]}