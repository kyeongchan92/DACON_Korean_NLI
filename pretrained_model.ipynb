{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pretrained_model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyM5nq1UX7wqGYXMRFGA2h7Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c66b2d9eac6644d2ad1bac6681c00ca7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e1117cb2ace4ed98771b28f9034b2bc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2bd1c0b47e3845e69433a0e86ea1158c","IPY_MODEL_02d92dec0f0b4661b3b478d238dd4166","IPY_MODEL_3f51559db25e4a6283c69b8b2112a75a"]}},"1e1117cb2ace4ed98771b28f9034b2bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2bd1c0b47e3845e69433a0e86ea1158c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3ef70b35e6d842bba8eb3b3408154a68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10e9155d8a0a4492a9d33cbd3a65d102"}},"02d92dec0f0b4661b3b478d238dd4166":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2b8faffd717349b7abf7598f2003f12a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":467,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_913b875e44844fb1ba969d83689ae528"}},"3f51559db25e4a6283c69b8b2112a75a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d026b3c182e641e39d7aa670b669c378","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467/467 [00:00&lt;00:00, 18.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1883d8a14a804e6daa95f7b85f5c0858"}},"3ef70b35e6d842bba8eb3b3408154a68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"10e9155d8a0a4492a9d33cbd3a65d102":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b8faffd717349b7abf7598f2003f12a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"913b875e44844fb1ba969d83689ae528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d026b3c182e641e39d7aa670b669c378":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1883d8a14a804e6daa95f7b85f5c0858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d9a986f3bd54f9c986b5c2728236853":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9066464ad9204d77b9db30a129a7776c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9aa741003284fe7bc5b21c8c1e8e1af","IPY_MODEL_be6d4f88c5cc46ce974af8dec50e9ccb","IPY_MODEL_b2ba6511f59741c7abfe662b55889a1d"]}},"9066464ad9204d77b9db30a129a7776c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9aa741003284fe7bc5b21c8c1e8e1af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a593eb2f4584c51800f39347dc87de2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b066deda42c349b7b8e7f1618dd3b928"}},"be6d4f88c5cc46ce974af8dec50e9ccb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ee776a206a5d4a63b1bde4af288838f2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":451741507,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":451741507,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b5fd0192ca6435d87bc66dede0c4c99"}},"b2ba6511f59741c7abfe662b55889a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a0db0bf0535d4472b7fda1726e1726d2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 431M/431M [00:07&lt;00:00, 56.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01244e99f5e54a2eba8996e99a7de77e"}},"2a593eb2f4584c51800f39347dc87de2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b066deda42c349b7b8e7f1618dd3b928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee776a206a5d4a63b1bde4af288838f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b5fd0192ca6435d87bc66dede0c4c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0db0bf0535d4472b7fda1726e1726d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"01244e99f5e54a2eba8996e99a7de77e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3113cb42834e4093a548b064222c6376":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3ce47292d3f64163afeb10734a202d6a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dda6f6e4ca7845429d7920c47c4cd149","IPY_MODEL_27be6cb9df3d4cd5b327f4fd11c3e9b7","IPY_MODEL_e2e7e57fe675401a83c06a141c73740a"]}},"3ce47292d3f64163afeb10734a202d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dda6f6e4ca7845429d7920c47c4cd149":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8749f4dbdc89432f9833d6180d6ead43","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_773fca42360942f7abd8029dc147636e"}},"27be6cb9df3d4cd5b327f4fd11c3e9b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_735d4ae2c2ce42a8b330326a80acb9fb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":61,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":61,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ee850137c4d4fb2a299aebc3335f0bd"}},"e2e7e57fe675401a83c06a141c73740a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c734925149df43fe959cd44e1c6e3b46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 61.0/61.0 [00:00&lt;00:00, 2.53kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e02585e7097744f3b982caaf9830d3f8"}},"8749f4dbdc89432f9833d6180d6ead43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"773fca42360942f7abd8029dc147636e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"735d4ae2c2ce42a8b330326a80acb9fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6ee850137c4d4fb2a299aebc3335f0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c734925149df43fe959cd44e1c6e3b46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e02585e7097744f3b982caaf9830d3f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f53f7e4b3883456fb0f962662dce5ad4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e5c4ecae26b4b559c17372d796e2dc7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b86492eb8fdb473d9cffca9d7fc46e27","IPY_MODEL_3c423e7057be469d8b8155470ad1ddde","IPY_MODEL_730fa15d09c14f6cbcc67e20b5234ded"]}},"6e5c4ecae26b4b559c17372d796e2dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b86492eb8fdb473d9cffca9d7fc46e27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8815f61983344c68d2b42d56964ad31","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_70656928994243d2a5d70006fd1162d7"}},"3c423e7057be469d8b8155470ad1ddde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1b00f4add3d44f4585d98788cfea53d1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":263326,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":263326,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_361fdcd611d74794bc941858ecd72bfc"}},"730fa15d09c14f6cbcc67e20b5234ded":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_172fd424f0a1476ab9ae5455011ddc03","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 257k/257k [00:00&lt;00:00, 710kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea2384fc9a914679b969d8006f01ad9a"}},"f8815f61983344c68d2b42d56964ad31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"70656928994243d2a5d70006fd1162d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b00f4add3d44f4585d98788cfea53d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"361fdcd611d74794bc941858ecd72bfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"172fd424f0a1476ab9ae5455011ddc03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ea2384fc9a914679b969d8006f01ad9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# 0 설정, 설치 임포트"],"metadata":{"id":"2Gdm7kFeAxq8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bbkvzkru6NE","executionInfo":{"status":"ok","timestamp":1644680690908,"user_tz":-540,"elapsed":23395,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"8f1401a3-616c-4a80-b684-45a24d464ea7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/015GithubRepos/Dacon_sentence_classification')"],"metadata":{"id":"lHrIc-pcu7px","executionInfo":{"status":"ok","timestamp":1644680692660,"user_tz":-540,"elapsed":1762,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"id":"0RSyNx8K2N3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644680702869,"user_tz":-540,"elapsed":10216,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"0afb1a38-de70-47d5-e70c-98866c0cb425"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 5.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 3.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 60.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 51.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 53.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"F6V0Z07B-QAj","executionInfo":{"status":"ok","timestamp":1644680712375,"user_tz":-540,"elapsed":9521,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"outputs":[],"source":["import pandas as pd \n","import numpy as np \n","import re\n","from tqdm import tqdm\n","import time\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW, AutoModel, AutoModelForSequenceClassification\n","from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","\n","from sklearn.model_selection import train_test_split\n","\n","import warnings \n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","source":["## 경로지정"],"metadata":{"id":"MEkZ0XW30Phe"}},{"cell_type":"code","source":["# local = 'C:/Users/posick/Desktop/Dacon/open/'\n","# local2 = 'C:/Users/201/Desktop/Dacon/'\n","suv = 'data/'\n","# colab = '/content/drive/MyDrive/Dacon/'"],"metadata":{"id":"32_POXlN_Ivm","executionInfo":{"status":"ok","timestamp":1644680713648,"user_tz":-540,"elapsed":2,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# 1 하이퍼 파라미터 설정"],"metadata":{"id":"ND_NDPEFA1tZ"}},{"cell_type":"markdown","source":["### epoch"],"metadata":{"id":"CHGZsITh07gc"}},{"cell_type":"code","source":["# epoch 5만 해도될듯\n","num_epochs = 10"],"metadata":{"id":"kG_U2QQA_JuP","executionInfo":{"status":"ok","timestamp":1644680715302,"user_tz":-540,"elapsed":2,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### batch_size"],"metadata":{"id":"-WOD-UX908s2"}},{"cell_type":"code","source":["batch_size = 32"],"metadata":{"id":"1mojsDjg05te","executionInfo":{"status":"ok","timestamp":1644680715614,"user_tz":-540,"elapsed":3,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### learning rate"],"metadata":{"id":"cUuZvTYw1AKv"}},{"cell_type":"code","source":["lr = 0.00001"],"metadata":{"id":"32Nah8EK05V2","executionInfo":{"status":"ok","timestamp":1644680716939,"user_tz":-540,"elapsed":2,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# 2 Data 처리"],"metadata":{"id":"ZtBHXrxSXoUn"}},{"cell_type":"markdown","source":["## 텍스트 전처리"],"metadata":{"id":"tuQZ2t2xl6t3"}},{"cell_type":"code","source":["# dev 데이터 더함\n","\n","def load_data(path):\n","    train = pd.read_csv(path+'train_data.csv')\n","    test = pd.read_csv(path+'test_data.csv')\n","    train_dev = pd.read_csv(path+'train_dev.csv')\n","    sample_submission = pd.read_csv(path+'sample_submission.csv')\n","\n","    train = pd.concat([train,train_dev], ignore_index=True)\n","\n","    label_dict = {\"entailment\" : 0, \"contradiction\" : 1, \"neutral\" : 2}\n","\n","    train['label'] = train['label'].map(label_dict)\n","    train['premise']=train['premise'].map(lambda x: re.sub('[-=+.,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', x))\n","    train['hypothesis']=train['hypothesis'].map(lambda x: re.sub('[-=+.,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', x))\n","    test['premise']=test['premise'].map(lambda x: re.sub('[-=+.,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', x))\n","    test['hypothesis']=test['hypothesis'].map(lambda x: re.sub('[-=+.,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', x))\n","\n","    return train,test,sample_submission \n","\n","def text_clean(df):\n","    df[\"premise_\"] = \"[CLS]\" + df[\"premise\"] + \"[SEP]\"\n","    df[\"hypothesis_\"] = df[\"hypothesis\"] + \"[SEP]\"\n","    df[\"text_sum\"] = df.premise_ + \" \" + df.hypothesis_\n","    df = df[['text_sum','label']]\n","\n","    return df \n","\n","train, test, sample_submission = load_data(suv)\n","clean_train, clean_test = text_clean(train), text_clean(test)\n"],"metadata":{"id":"MWjH3kggRULX","executionInfo":{"status":"ok","timestamp":1644680718865,"user_tz":-540,"elapsed":1382,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## CustomDataset 클래스 선언"],"metadata":{"id":"gWvB_6Ob3DiX"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"P5wiWaze4GVs"}},{"cell_type":"code","source":["#%% data loader \n","\n","class CustomDataset(Dataset):\n","  \n","  def __init__(self, dataset, option, modelname):\n","    self.dataset = dataset \n","    self.option = option\n","    self.tokenizer = AutoTokenizer.from_pretrained(modelname)\n","  \n","  def __len__(self):\n","    return len(self.dataset)\n","  \n","  def __getitem__(self, idx):\n","    row = self.dataset.iloc[idx, 0:2].values  # numpy array\n","    text = row[0]\n","    # y = row[1]\n","\n","    inputs = self.tokenizer(\n","        text, \n","        return_tensors='pt',\n","        truncation=True,\n","        max_length=70,\n","        pad_to_max_length=True,\n","        add_special_tokens=False\n","        )\n","    \n","    input_ids = inputs['input_ids'][0]\n","    attention_mask = inputs['attention_mask'][0]\n","    \n","    if self.option =='train':\n","        y = row[1]\n","        return input_ids, attention_mask, y\n","\n","    return input_ids, attention_mask\n"],"metadata":{"id":"FsaMk4cx_Jo6","executionInfo":{"status":"ok","timestamp":1644680720032,"user_tz":-540,"elapsed":6,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## CrossValidation 인덱스 생성"],"metadata":{"id":"bRcDqaDo3JKs"}},{"cell_type":"code","source":["#%% Cross validation \n","\n","n_splits = 5\n","\n","from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits = n_splits, shuffle=True, random_state=42)\n","\n","folds=[]\n","for trn_idx, val_idx in skf.split(clean_train['text_sum'], clean_train['label']):\n","    folds.append((trn_idx,val_idx))"],"metadata":{"id":"D0jGYi2y_Jm1","executionInfo":{"status":"ok","timestamp":1644680720034,"user_tz":-540,"elapsed":7,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# 학습"],"metadata":{"id":"KNIgrv-6Aukd"}},{"cell_type":"markdown","source":["## device 설정"],"metadata":{"id":"TXQZoELs0coo"}},{"cell_type":"code","source":["device = torch.device(\"cuda\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTADE8FgDEWJ","executionInfo":{"status":"ok","timestamp":1644680721019,"user_tz":-540,"elapsed":315,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"9d0c192f-d084-4874-f36a-8f8555c786be"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## 학습"],"metadata":{"id":"9lPggrbc1Els"}},{"cell_type":"markdown","source":["### modelname"],"metadata":{"id":"A0Rxog4nlPaL"}},{"cell_type":"code","source":["modelname = 'klue/roberta-large'\n","# modelname = 'monologg/koelectra-base-v3-discriminator'\n","modelname"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"mhm_TeLTwrol","executionInfo":{"status":"ok","timestamp":1644680722085,"user_tz":-540,"elapsed":15,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"241c5887-e804-4ba2-d8ad-37141064799b"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'klue/roberta-large'"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["best_models = []\n","model_num = 0\n","for fold in range(5):\n","    start_time = time.time()\n","    print(f'=============================={fold+1}fold start==============================')\n","\n","    # CV용 model 새로 선언\n","    model = AutoModelForSequenceClassification.from_pretrained(modelname, num_labels=3)\n","    model = nn.DataParallel(model).to(device)\n","    \n","    optimizer = AdamW(model.parameters(), lr=lr)\n","    \n","    train_idx = folds[fold][0]\n","    valid_idx = folds[fold][1]\n","\n","    train_data = clean_train.loc[train_idx]\n","    val_data = clean_train.loc[valid_idx]\n","\n","    train_dataset = CustomDataset(train_data, 'train', modelname)\n","    valid_dataset = CustomDataset(val_data, 'train', modelname)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","    \n","    warmup_ratio = 0.1\n","    total_steps = len(train_loader) * num_epochs\n","    warmup_step = int(total_steps * warmup_ratio)\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=total_steps)\n","    valid_loss_min = 0.4\n","    valid_acc_max = 0.8\n","    \n","    \n","    for epoch in range(num_epochs):  # epoch = 10\n","        print(f'epoch : {epoch}-----------------------------------------------------------------')\n","        batches = 0\n","        total_loss = 0.0\n","        correct = 0\n","        total =0\n","        model.train()  # train 모드로 변경\n","        \n","        # 학습데이터로 학습 #############################################################\n","        print(f'train 학습..........')\n","        for input_ids_batch, attention_masks_batch, y_batch in train_loader:\n","            optimizer.zero_grad()  # 그래디언트 초기화\n","            y_batch = y_batch.to(device)  # y_batch를 gpu 올림\n","            y_pred = model(input_ids_batch.to(device), attention_mask = attention_masks_batch.to(device))[0]  # 순전파\n","            loss = F.cross_entropy(y_pred, y_batch)  # loss 계산\n","            loss.backward()  # 역전파\n","            optimizer.step()  # 가중치 업데이트\n","            total_loss += loss.item()\n","            _, predicted = torch.max(y_pred, 1)\n","            correct += (predicted == y_batch).sum()\n","            total += len(y_batch)\n","            batches += 1\n","            if batches % 100 == 0:\n","                acc = correct.float() / total\n","                print(f'iteration 누적 : {batches}, Train Loss: {total_loss:.4f}, Train Accuracy : {acc.item():.4f}')\n","        acc = correct.float() / total\n","        print(f'iteration 누적 : {batches}, Train Loss: {total_loss:.4f}, Train Accuracy : {acc.item():.4f}')\n","        # 학습데이터로 학습 #############################################################\n","\n","\n","        # 검증데이터로 검증 #############################################################\n","        val_loss = []\n","        val_acc = []\n","        print(f'validation 검증..........')\n","        for input_ids_batch, attention_masks_batch, y_batch in valid_loader:\n","            \n","            model.eval()\n","            with torch.no_grad():\n","                y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n","                valid_loss = F.cross_entropy(y_pred,y_batch.to(device)).cpu().detach().numpy()\n","\n","                preds = torch.argmax(y_pred,1)\n","                preds = preds.cpu().detach().numpy()\n","                y_batch = y_batch.cpu().detach().numpy()\n","                batch_acc = (preds==y_batch).mean()\n","                val_loss.append(valid_loss)\n","                val_acc.append(batch_acc)\n","\n","        val_loss = np.mean(val_loss)\n","        val_acc = np.mean(val_acc)\n","        scheduler.step()\n","        print(f'Valid Loss: {val_loss:.4f}, Valid Accuracy : {val_acc:.4f}')\n","        print(f'Learning rate : {optimizer.param_groups[0][\"lr\"]:.6f}')\n","        # 검증데이터로 검증 #############################################################\n","\n","        if valid_acc_max < val_acc:  # 이전보다 좋으면 best_models에 모델을 추가\n","            valid_acc_max = val_acc\n","            best_models.append(model)\n","            torch.save(model, f'koelectra-adddata{model_num}.pth')  # 모델 저장\n","            model_num += 1\n","            print(f'model \\'koelectra-adddata{model_num}.pth\\' save. the number of best_models: {len(best_models)}, model val acc : {val_acc:.6f}******************')\n","        print(f'--------------------------------------------------------------------------------')\n","\n","    print(f'{fold+1}fold elapsed time : {time.time() - start_time}')\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c66b2d9eac6644d2ad1bac6681c00ca7","1e1117cb2ace4ed98771b28f9034b2bc","2bd1c0b47e3845e69433a0e86ea1158c","02d92dec0f0b4661b3b478d238dd4166","3f51559db25e4a6283c69b8b2112a75a","3ef70b35e6d842bba8eb3b3408154a68","10e9155d8a0a4492a9d33cbd3a65d102","2b8faffd717349b7abf7598f2003f12a","913b875e44844fb1ba969d83689ae528","d026b3c182e641e39d7aa670b669c378","1883d8a14a804e6daa95f7b85f5c0858","9d9a986f3bd54f9c986b5c2728236853","9066464ad9204d77b9db30a129a7776c","b9aa741003284fe7bc5b21c8c1e8e1af","be6d4f88c5cc46ce974af8dec50e9ccb","b2ba6511f59741c7abfe662b55889a1d","2a593eb2f4584c51800f39347dc87de2","b066deda42c349b7b8e7f1618dd3b928","ee776a206a5d4a63b1bde4af288838f2","3b5fd0192ca6435d87bc66dede0c4c99","a0db0bf0535d4472b7fda1726e1726d2","01244e99f5e54a2eba8996e99a7de77e","3113cb42834e4093a548b064222c6376","3ce47292d3f64163afeb10734a202d6a","dda6f6e4ca7845429d7920c47c4cd149","27be6cb9df3d4cd5b327f4fd11c3e9b7","e2e7e57fe675401a83c06a141c73740a","8749f4dbdc89432f9833d6180d6ead43","773fca42360942f7abd8029dc147636e","735d4ae2c2ce42a8b330326a80acb9fb","6ee850137c4d4fb2a299aebc3335f0bd","c734925149df43fe959cd44e1c6e3b46","e02585e7097744f3b982caaf9830d3f8","f53f7e4b3883456fb0f962662dce5ad4","6e5c4ecae26b4b559c17372d796e2dc7","b86492eb8fdb473d9cffca9d7fc46e27","3c423e7057be469d8b8155470ad1ddde","730fa15d09c14f6cbcc67e20b5234ded","f8815f61983344c68d2b42d56964ad31","70656928994243d2a5d70006fd1162d7","1b00f4add3d44f4585d98788cfea53d1","361fdcd611d74794bc941858ecd72bfc","172fd424f0a1476ab9ae5455011ddc03","ea2384fc9a914679b969d8006f01ad9a"]},"id":"ucFJyMFy_JlC","outputId":"7e8e50bd-256c-4efe-dcdf-66187e742257","executionInfo":{"status":"ok","timestamp":1644679772849,"user_tz":-540,"elapsed":9123533,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["==============================1fold start==============================\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c66b2d9eac6644d2ad1bac6681c00ca7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d9a986f3bd54f9c986b5c2728236853","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/431M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3113cb42834e4093a548b064222c6376","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f53f7e4b3883456fb0f962662dce5ad4","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/257k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch : 0-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 109.9769, Train Accuracy : 0.3262\n","Batch : 200, Train Loss: 219.9861, Train Accuracy : 0.3253\n","Batch : 300, Train Loss: 329.8607, Train Accuracy : 0.3300\n","Batch : 400, Train Loss: 439.8445, Train Accuracy : 0.3293\n","Batch : 500, Train Loss: 549.7905, Train Accuracy : 0.3274\n","Batch : 600, Train Loss: 659.7315, Train Accuracy : 0.3276\n","Batch : 700, Train Loss: 769.7412, Train Accuracy : 0.3280\n","Batch 누적 : 700, Train Loss: 769.7412, Train Accuracy : 0.3280\n","validation 검증..........\n","Valid Loss: 1.0994, Valid Accuracy : 0.3179\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 1-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 104.8061, Train Accuracy : 0.4834\n","Batch : 200, Train Loss: 170.7515, Train Accuracy : 0.6255\n","Batch : 300, Train Loss: 223.2042, Train Accuracy : 0.6855\n","Batch : 400, Train Loss: 271.5507, Train Accuracy : 0.7197\n","Batch : 500, Train Loss: 316.5275, Train Accuracy : 0.7421\n","Batch : 600, Train Loss: 359.3519, Train Accuracy : 0.7593\n","Batch : 700, Train Loss: 401.8628, Train Accuracy : 0.7704\n","Batch 누적 : 700, Train Loss: 401.8628, Train Accuracy : 0.7704\n","validation 검증..........\n","Valid Loss: 0.3578, Valid Accuracy : 0.8716\n","Learning rate : 0.000010\n","model 'koelectra-adddata1.pth' save. the number of best_models: 1, model val acc : 0.871578******************\n","--------------------------------------------------------------------------------\n","epoch : 2-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 29.8065, Train Accuracy : 0.8991\n","Batch : 200, Train Loss: 59.6498, Train Accuracy : 0.8966\n","Batch : 300, Train Loss: 86.4560, Train Accuracy : 0.8996\n","Batch : 400, Train Loss: 116.4299, Train Accuracy : 0.8979\n","Batch : 500, Train Loss: 146.0628, Train Accuracy : 0.8978\n","Batch : 600, Train Loss: 176.3551, Train Accuracy : 0.8976\n","Batch : 700, Train Loss: 203.5035, Train Accuracy : 0.8988\n","Batch 누적 : 700, Train Loss: 203.5035, Train Accuracy : 0.8988\n","validation 검증..........\n","Valid Loss: 0.3545, Valid Accuracy : 0.8755\n","Learning rate : 0.000010\n","model 'koelectra-adddata2.pth' save. the number of best_models: 2, model val acc : 0.875518******************\n","--------------------------------------------------------------------------------\n","epoch : 3-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 19.0970, Train Accuracy : 0.9406\n","Batch : 200, Train Loss: 36.7799, Train Accuracy : 0.9425\n","Batch : 300, Train Loss: 53.8632, Train Accuracy : 0.9417\n","Batch : 400, Train Loss: 72.9545, Train Accuracy : 0.9393\n","Batch : 500, Train Loss: 92.6912, Train Accuracy : 0.9384\n","Batch : 600, Train Loss: 112.1003, Train Accuracy : 0.9378\n","Batch : 700, Train Loss: 131.6167, Train Accuracy : 0.9376\n","Batch 누적 : 700, Train Loss: 131.6167, Train Accuracy : 0.9376\n","validation 검증..........\n","Valid Loss: 0.3563, Valid Accuracy : 0.8812\n","Learning rate : 0.000010\n","model 'koelectra-adddata3.pth' save. the number of best_models: 3, model val acc : 0.881221******************\n","--------------------------------------------------------------------------------\n","epoch : 4-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 12.3283, Train Accuracy : 0.9653\n","Batch : 200, Train Loss: 23.4440, Train Accuracy : 0.9652\n","Batch : 300, Train Loss: 35.1041, Train Accuracy : 0.9649\n","Batch : 400, Train Loss: 48.1817, Train Accuracy : 0.9633\n","Batch : 500, Train Loss: 61.1879, Train Accuracy : 0.9626\n","Batch : 600, Train Loss: 72.8108, Train Accuracy : 0.9626\n","Batch : 700, Train Loss: 86.4096, Train Accuracy : 0.9614\n","Batch 누적 : 700, Train Loss: 86.4096, Train Accuracy : 0.9614\n","validation 검증..........\n","Valid Loss: 0.3918, Valid Accuracy : 0.8855\n","Learning rate : 0.000010\n","model 'koelectra-adddata4.pth' save. the number of best_models: 4, model val acc : 0.885507******************\n","--------------------------------------------------------------------------------\n","epoch : 5-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 7.4117, Train Accuracy : 0.9778\n","Batch : 200, Train Loss: 15.6351, Train Accuracy : 0.9756\n","Batch : 300, Train Loss: 24.8082, Train Accuracy : 0.9746\n","Batch : 400, Train Loss: 34.0985, Train Accuracy : 0.9734\n","Batch : 500, Train Loss: 41.8695, Train Accuracy : 0.9743\n","Batch : 600, Train Loss: 49.5270, Train Accuracy : 0.9746\n","Batch : 700, Train Loss: 57.9723, Train Accuracy : 0.9745\n","Batch 누적 : 700, Train Loss: 57.9723, Train Accuracy : 0.9745\n","validation 검증..........\n","Valid Loss: 0.4557, Valid Accuracy : 0.8800\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 6-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 5.3162, Train Accuracy : 0.9850\n","Batch : 200, Train Loss: 12.2113, Train Accuracy : 0.9831\n","Batch : 300, Train Loss: 18.1848, Train Accuracy : 0.9832\n","Batch : 400, Train Loss: 24.3717, Train Accuracy : 0.9826\n","Batch : 500, Train Loss: 31.3453, Train Accuracy : 0.9818\n","Batch : 600, Train Loss: 37.0309, Train Accuracy : 0.9822\n","Batch : 700, Train Loss: 42.8575, Train Accuracy : 0.9821\n","Batch 누적 : 700, Train Loss: 42.8575, Train Accuracy : 0.9821\n","validation 검증..........\n","Valid Loss: 0.4739, Valid Accuracy : 0.8851\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 7-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 4.9803, Train Accuracy : 0.9853\n","Batch : 200, Train Loss: 8.6532, Train Accuracy : 0.9867\n","Batch : 300, Train Loss: 13.3015, Train Accuracy : 0.9859\n","Batch : 400, Train Loss: 19.1204, Train Accuracy : 0.9859\n","Batch : 500, Train Loss: 24.0847, Train Accuracy : 0.9854\n","Batch : 600, Train Loss: 30.1032, Train Accuracy : 0.9848\n","Batch : 700, Train Loss: 35.0824, Train Accuracy : 0.9847\n","Batch 누적 : 700, Train Loss: 35.0824, Train Accuracy : 0.9847\n","validation 검증..........\n","Valid Loss: 0.5126, Valid Accuracy : 0.8860\n","Learning rate : 0.000010\n","model 'koelectra-adddata5.pth' save. the number of best_models: 5, model val acc : 0.886043******************\n","--------------------------------------------------------------------------------\n","epoch : 8-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.0523, Train Accuracy : 0.9894\n","Batch : 200, Train Loss: 6.5724, Train Accuracy : 0.9891\n","Batch : 300, Train Loss: 10.6539, Train Accuracy : 0.9886\n","Batch : 400, Train Loss: 14.6282, Train Accuracy : 0.9882\n","Batch : 500, Train Loss: 17.9403, Train Accuracy : 0.9886\n","Batch : 600, Train Loss: 22.0919, Train Accuracy : 0.9886\n","Batch : 700, Train Loss: 26.5664, Train Accuracy : 0.9884\n","Batch 누적 : 700, Train Loss: 26.5664, Train Accuracy : 0.9884\n","validation 검증..........\n","Valid Loss: 0.5473, Valid Accuracy : 0.8816\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 9-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.5240, Train Accuracy : 0.9900\n","Batch : 200, Train Loss: 6.4212, Train Accuracy : 0.9903\n","Batch : 300, Train Loss: 10.5876, Train Accuracy : 0.9899\n","Batch : 400, Train Loss: 13.6490, Train Accuracy : 0.9905\n","Batch : 500, Train Loss: 15.9517, Train Accuracy : 0.9910\n","Batch : 600, Train Loss: 18.8668, Train Accuracy : 0.9911\n","Batch : 700, Train Loss: 23.2096, Train Accuracy : 0.9904\n","Batch 누적 : 700, Train Loss: 23.2096, Train Accuracy : 0.9904\n","validation 검증..........\n","Valid Loss: 0.5665, Valid Accuracy : 0.8816\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","1fold elapsed time : 1842.7800753116608\n","==============================2fold start==============================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["epoch : 0-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 109.8392, Train Accuracy : 0.3550\n","Batch : 200, Train Loss: 219.8459, Train Accuracy : 0.3487\n","Batch : 300, Train Loss: 329.6248, Train Accuracy : 0.3522\n","Batch : 400, Train Loss: 439.6365, Train Accuracy : 0.3496\n","Batch : 500, Train Loss: 549.5495, Train Accuracy : 0.3489\n","Batch : 600, Train Loss: 659.5355, Train Accuracy : 0.3465\n","Batch : 700, Train Loss: 769.5228, Train Accuracy : 0.3460\n","Batch 누적 : 700, Train Loss: 769.5228, Train Accuracy : 0.3460\n","validation 검증..........\n","Valid Loss: 1.0986, Valid Accuracy : 0.3395\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 1-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 103.7221, Train Accuracy : 0.4887\n","Batch : 200, Train Loss: 165.9060, Train Accuracy : 0.6383\n","Batch : 300, Train Loss: 219.8783, Train Accuracy : 0.6917\n","Batch : 400, Train Loss: 265.7670, Train Accuracy : 0.7262\n","Batch : 500, Train Loss: 309.0063, Train Accuracy : 0.7493\n","Batch : 600, Train Loss: 352.7456, Train Accuracy : 0.7636\n","Batch : 700, Train Loss: 391.9826, Train Accuracy : 0.7768\n","Batch 누적 : 700, Train Loss: 391.9826, Train Accuracy : 0.7768\n","validation 검증..........\n","Valid Loss: 0.3922, Valid Accuracy : 0.8571\n","Learning rate : 0.000010\n","model 'koelectra-adddata6.pth' save. the number of best_models: 6, model val acc : 0.857126******************\n","--------------------------------------------------------------------------------\n","epoch : 2-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 29.3059, Train Accuracy : 0.8978\n","Batch : 200, Train Loss: 60.3476, Train Accuracy : 0.8981\n","Batch : 300, Train Loss: 90.4701, Train Accuracy : 0.8972\n","Batch : 400, Train Loss: 117.9699, Train Accuracy : 0.9000\n","Batch : 500, Train Loss: 142.3739, Train Accuracy : 0.9031\n","Batch : 600, Train Loss: 169.1816, Train Accuracy : 0.9039\n","Batch : 700, Train Loss: 197.3532, Train Accuracy : 0.9037\n","Batch 누적 : 700, Train Loss: 197.3532, Train Accuracy : 0.9037\n","validation 검증..........\n","Valid Loss: 0.3785, Valid Accuracy : 0.8664\n","Learning rate : 0.000010\n","model 'koelectra-adddata7.pth' save. the number of best_models: 7, model val acc : 0.866400******************\n","--------------------------------------------------------------------------------\n","epoch : 3-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 16.1221, Train Accuracy : 0.9475\n","Batch : 200, Train Loss: 33.1165, Train Accuracy : 0.9473\n","Batch : 300, Train Loss: 51.3996, Train Accuracy : 0.9444\n","Batch : 400, Train Loss: 68.5841, Train Accuracy : 0.9443\n","Batch : 500, Train Loss: 88.6479, Train Accuracy : 0.9421\n","Batch : 600, Train Loss: 106.7234, Train Accuracy : 0.9422\n","Batch : 700, Train Loss: 125.6988, Train Accuracy : 0.9419\n","Batch 누적 : 700, Train Loss: 125.6988, Train Accuracy : 0.9419\n","validation 검증..........\n","Valid Loss: 0.4032, Valid Accuracy : 0.8762\n","Learning rate : 0.000010\n","model 'koelectra-adddata8.pth' save. the number of best_models: 8, model val acc : 0.876238******************\n","--------------------------------------------------------------------------------\n","epoch : 4-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 11.7177, Train Accuracy : 0.9653\n","Batch : 200, Train Loss: 24.2345, Train Accuracy : 0.9617\n","Batch : 300, Train Loss: 35.3864, Train Accuracy : 0.9639\n","Batch : 400, Train Loss: 47.1327, Train Accuracy : 0.9646\n","Batch : 500, Train Loss: 59.4028, Train Accuracy : 0.9634\n","Batch : 600, Train Loss: 73.0556, Train Accuracy : 0.9621\n","Batch : 700, Train Loss: 84.7956, Train Accuracy : 0.9624\n","Batch 누적 : 700, Train Loss: 84.7956, Train Accuracy : 0.9624\n","validation 검증..........\n","Valid Loss: 0.4767, Valid Accuracy : 0.8675\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 5-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 7.7399, Train Accuracy : 0.9806\n","Batch : 200, Train Loss: 14.6216, Train Accuracy : 0.9798\n","Batch : 300, Train Loss: 22.3764, Train Accuracy : 0.9788\n","Batch : 400, Train Loss: 30.5272, Train Accuracy : 0.9774\n","Batch : 500, Train Loss: 38.0471, Train Accuracy : 0.9771\n","Batch : 600, Train Loss: 48.2510, Train Accuracy : 0.9761\n","Batch : 700, Train Loss: 56.1522, Train Accuracy : 0.9759\n","Batch 누적 : 700, Train Loss: 56.1522, Train Accuracy : 0.9759\n","validation 검증..........\n","Valid Loss: 0.4918, Valid Accuracy : 0.8734\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 6-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 5.6614, Train Accuracy : 0.9831\n","Batch : 200, Train Loss: 12.2126, Train Accuracy : 0.9836\n","Batch : 300, Train Loss: 17.6798, Train Accuracy : 0.9831\n","Batch : 400, Train Loss: 24.5883, Train Accuracy : 0.9822\n","Batch : 500, Train Loss: 30.5037, Train Accuracy : 0.9826\n","Batch : 600, Train Loss: 36.2874, Train Accuracy : 0.9828\n","Batch : 700, Train Loss: 42.5242, Train Accuracy : 0.9827\n","Batch 누적 : 700, Train Loss: 42.5242, Train Accuracy : 0.9827\n","validation 검증..........\n","Valid Loss: 0.5362, Valid Accuracy : 0.8745\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 7-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 2.9845, Train Accuracy : 0.9912\n","Batch : 200, Train Loss: 7.7433, Train Accuracy : 0.9883\n","Batch : 300, Train Loss: 12.4110, Train Accuracy : 0.9873\n","Batch : 400, Train Loss: 17.5793, Train Accuracy : 0.9862\n","Batch : 500, Train Loss: 21.2567, Train Accuracy : 0.9870\n","Batch : 600, Train Loss: 26.0254, Train Accuracy : 0.9868\n","Batch : 700, Train Loss: 31.4223, Train Accuracy : 0.9862\n","Batch 누적 : 700, Train Loss: 31.4223, Train Accuracy : 0.9862\n","validation 검증..........\n","Valid Loss: 0.5713, Valid Accuracy : 0.8735\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 8-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 2.5366, Train Accuracy : 0.9925\n","Batch : 200, Train Loss: 7.4530, Train Accuracy : 0.9883\n","Batch : 300, Train Loss: 11.2663, Train Accuracy : 0.9890\n","Batch : 400, Train Loss: 15.2769, Train Accuracy : 0.9885\n","Batch : 500, Train Loss: 19.3283, Train Accuracy : 0.9881\n","Batch : 600, Train Loss: 24.0067, Train Accuracy : 0.9876\n","Batch : 700, Train Loss: 28.6100, Train Accuracy : 0.9870\n","Batch 누적 : 700, Train Loss: 28.6100, Train Accuracy : 0.9870\n","validation 검증..........\n","Valid Loss: 0.5871, Valid Accuracy : 0.8702\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 9-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.1525, Train Accuracy : 0.9909\n","Batch : 200, Train Loss: 6.4162, Train Accuracy : 0.9917\n","Batch : 300, Train Loss: 8.7967, Train Accuracy : 0.9925\n","Batch : 400, Train Loss: 12.4193, Train Accuracy : 0.9912\n","Batch : 500, Train Loss: 15.7058, Train Accuracy : 0.9909\n","Batch : 600, Train Loss: 19.9388, Train Accuracy : 0.9905\n","Batch : 700, Train Loss: 23.3713, Train Accuracy : 0.9904\n","Batch 누적 : 700, Train Loss: 23.3713, Train Accuracy : 0.9904\n","validation 검증..........\n","Valid Loss: 0.6583, Valid Accuracy : 0.8684\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","2fold elapsed time : 1816.5549948215485\n","==============================3fold start==============================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["epoch : 0-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 109.7429, Train Accuracy : 0.3541\n","Batch : 200, Train Loss: 219.7632, Train Accuracy : 0.3469\n","Batch : 300, Train Loss: 329.7021, Train Accuracy : 0.3470\n","Batch : 400, Train Loss: 439.8077, Train Accuracy : 0.3439\n","Batch : 500, Train Loss: 549.9281, Train Accuracy : 0.3408\n","Batch : 600, Train Loss: 659.8600, Train Accuracy : 0.3407\n","Batch : 700, Train Loss: 769.7101, Train Accuracy : 0.3423\n","Batch 누적 : 700, Train Loss: 769.7101, Train Accuracy : 0.3423\n","validation 검증..........\n","Valid Loss: 1.0989, Valid Accuracy : 0.3431\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 1-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 105.5377, Train Accuracy : 0.4762\n","Batch : 200, Train Loss: 172.7548, Train Accuracy : 0.6170\n","Batch : 300, Train Loss: 229.6980, Train Accuracy : 0.6757\n","Batch : 400, Train Loss: 289.4122, Train Accuracy : 0.6975\n","Batch : 500, Train Loss: 343.9404, Train Accuracy : 0.7157\n","Batch : 600, Train Loss: 396.3099, Train Accuracy : 0.7289\n","Batch : 700, Train Loss: 446.9043, Train Accuracy : 0.7400\n","Batch 누적 : 700, Train Loss: 446.9043, Train Accuracy : 0.7400\n","validation 검증..........\n","Valid Loss: 0.4530, Valid Accuracy : 0.8344\n","Learning rate : 0.000010\n","model 'koelectra-adddata9.pth' save. the number of best_models: 9, model val acc : 0.834357******************\n","--------------------------------------------------------------------------------\n","epoch : 2-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 40.9178, Train Accuracy : 0.8537\n","Batch : 200, Train Loss: 79.9858, Train Accuracy : 0.8573\n","Batch : 300, Train Loss: 118.0001, Train Accuracy : 0.8588\n","Batch : 400, Train Loss: 156.1084, Train Accuracy : 0.8601\n","Batch : 500, Train Loss: 195.7602, Train Accuracy : 0.8580\n","Batch : 600, Train Loss: 231.8609, Train Accuracy : 0.8601\n","Batch : 700, Train Loss: 265.1653, Train Accuracy : 0.8631\n","Batch 누적 : 700, Train Loss: 265.1653, Train Accuracy : 0.8631\n","validation 검증..........\n","Valid Loss: 0.4202, Valid Accuracy : 0.8544\n","Learning rate : 0.000010\n","model 'koelectra-adddata10.pth' save. the number of best_models: 10, model val acc : 0.854369******************\n","--------------------------------------------------------------------------------\n","epoch : 3-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 27.1059, Train Accuracy : 0.9112\n","Batch : 200, Train Loss: 54.7068, Train Accuracy : 0.9070\n","Batch : 300, Train Loss: 82.3806, Train Accuracy : 0.9054\n","Batch : 400, Train Loss: 106.7056, Train Accuracy : 0.9095\n","Batch : 500, Train Loss: 134.7568, Train Accuracy : 0.9074\n","Batch : 600, Train Loss: 161.3848, Train Accuracy : 0.9074\n","Batch : 700, Train Loss: 189.6054, Train Accuracy : 0.9061\n","Batch 누적 : 700, Train Loss: 189.6054, Train Accuracy : 0.9061\n","validation 검증..........\n","Valid Loss: 0.4377, Valid Accuracy : 0.8572\n","Learning rate : 0.000010\n","model 'koelectra-adddata11.pth' save. the number of best_models: 11, model val acc : 0.857226******************\n","--------------------------------------------------------------------------------\n","epoch : 4-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 18.7490, Train Accuracy : 0.9381\n","Batch : 200, Train Loss: 37.9529, Train Accuracy : 0.9369\n","Batch : 300, Train Loss: 58.0178, Train Accuracy : 0.9353\n","Batch : 400, Train Loss: 78.4941, Train Accuracy : 0.9345\n","Batch : 500, Train Loss: 97.9720, Train Accuracy : 0.9347\n","Batch : 600, Train Loss: 117.9644, Train Accuracy : 0.9345\n","Batch : 700, Train Loss: 138.6763, Train Accuracy : 0.9338\n","Batch 누적 : 700, Train Loss: 138.6763, Train Accuracy : 0.9338\n","validation 검증..........\n","Valid Loss: 0.4300, Valid Accuracy : 0.8624\n","Learning rate : 0.000010\n","model 'koelectra-adddata12.pth' save. the number of best_models: 12, model val acc : 0.862429******************\n","--------------------------------------------------------------------------------\n","epoch : 5-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 13.5972, Train Accuracy : 0.9578\n","Batch : 200, Train Loss: 28.0704, Train Accuracy : 0.9545\n","Batch : 300, Train Loss: 42.8113, Train Accuracy : 0.9531\n","Batch : 400, Train Loss: 57.2862, Train Accuracy : 0.9530\n","Batch : 500, Train Loss: 72.4182, Train Accuracy : 0.9524\n","Batch : 600, Train Loss: 88.0151, Train Accuracy : 0.9521\n","Batch : 700, Train Loss: 103.6733, Train Accuracy : 0.9515\n","Batch 누적 : 700, Train Loss: 103.6733, Train Accuracy : 0.9515\n","validation 검증..........\n","Valid Loss: 0.4633, Valid Accuracy : 0.8635\n","Learning rate : 0.000010\n","model 'koelectra-adddata13.pth' save. the number of best_models: 13, model val acc : 0.863488******************\n","--------------------------------------------------------------------------------\n","epoch : 6-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 10.8963, Train Accuracy : 0.9653\n","Batch : 200, Train Loss: 22.8707, Train Accuracy : 0.9647\n","Batch : 300, Train Loss: 33.6319, Train Accuracy : 0.9647\n","Batch : 400, Train Loss: 43.9766, Train Accuracy : 0.9655\n","Batch : 500, Train Loss: 54.9320, Train Accuracy : 0.9651\n","Batch : 600, Train Loss: 66.2660, Train Accuracy : 0.9647\n","Batch : 700, Train Loss: 78.0124, Train Accuracy : 0.9640\n","Batch 누적 : 700, Train Loss: 78.0124, Train Accuracy : 0.9640\n","validation 검증..........\n","Valid Loss: 0.5267, Valid Accuracy : 0.8648\n","Learning rate : 0.000010\n","model 'koelectra-adddata14.pth' save. the number of best_models: 14, model val acc : 0.864750******************\n","--------------------------------------------------------------------------------\n","epoch : 7-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 6.5228, Train Accuracy : 0.9787\n","Batch : 200, Train Loss: 15.2690, Train Accuracy : 0.9767\n","Batch : 300, Train Loss: 23.4916, Train Accuracy : 0.9767\n","Batch : 400, Train Loss: 32.6200, Train Accuracy : 0.9751\n","Batch : 500, Train Loss: 41.7080, Train Accuracy : 0.9741\n","Batch : 600, Train Loss: 50.9118, Train Accuracy : 0.9734\n","Batch : 700, Train Loss: 60.7091, Train Accuracy : 0.9725\n","Batch 누적 : 700, Train Loss: 60.7091, Train Accuracy : 0.9725\n","validation 검증..........\n","Valid Loss: 0.5642, Valid Accuracy : 0.8599\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 8-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 6.2112, Train Accuracy : 0.9787\n","Batch : 200, Train Loss: 12.3896, Train Accuracy : 0.9797\n","Batch : 300, Train Loss: 18.5488, Train Accuracy : 0.9800\n","Batch : 400, Train Loss: 26.5269, Train Accuracy : 0.9783\n","Batch : 500, Train Loss: 33.3445, Train Accuracy : 0.9783\n","Batch : 600, Train Loss: 40.3969, Train Accuracy : 0.9782\n","Batch : 700, Train Loss: 48.3735, Train Accuracy : 0.9775\n","Batch 누적 : 700, Train Loss: 48.3735, Train Accuracy : 0.9775\n","validation 검증..........\n","Valid Loss: 0.5857, Valid Accuracy : 0.8610\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 9-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 5.0035, Train Accuracy : 0.9866\n","Batch : 200, Train Loss: 11.5135, Train Accuracy : 0.9841\n","Batch : 300, Train Loss: 18.0019, Train Accuracy : 0.9831\n","Batch : 400, Train Loss: 24.6751, Train Accuracy : 0.9822\n","Batch : 500, Train Loss: 31.8782, Train Accuracy : 0.9811\n","Batch : 600, Train Loss: 38.2086, Train Accuracy : 0.9807\n","Batch : 700, Train Loss: 42.8815, Train Accuracy : 0.9814\n","Batch 누적 : 700, Train Loss: 42.8815, Train Accuracy : 0.9814\n","validation 검증..........\n","Valid Loss: 0.6264, Valid Accuracy : 0.8637\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","3fold elapsed time : 1822.700213432312\n","==============================4fold start==============================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["epoch : 0-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 110.2279, Train Accuracy : 0.3475\n","Batch : 200, Train Loss: 220.2652, Train Accuracy : 0.3428\n","Batch : 300, Train Loss: 330.5144, Train Accuracy : 0.3410\n","Batch : 400, Train Loss: 440.7746, Train Accuracy : 0.3366\n","Batch : 500, Train Loss: 550.9394, Train Accuracy : 0.3368\n","Batch : 600, Train Loss: 661.1805, Train Accuracy : 0.3351\n","Batch : 700, Train Loss: 771.3084, Train Accuracy : 0.3355\n","Batch 누적 : 700, Train Loss: 771.3084, Train Accuracy : 0.3355\n","validation 검증..........\n","Valid Loss: 1.1026, Valid Accuracy : 0.3326\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 1-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 104.5985, Train Accuracy : 0.4753\n","Batch : 200, Train Loss: 172.4253, Train Accuracy : 0.6109\n","Batch : 300, Train Loss: 223.9137, Train Accuracy : 0.6779\n","Batch : 400, Train Loss: 272.2241, Train Accuracy : 0.7145\n","Batch : 500, Train Loss: 316.8371, Train Accuracy : 0.7382\n","Batch : 600, Train Loss: 360.4703, Train Accuracy : 0.7542\n","Batch : 700, Train Loss: 401.6833, Train Accuracy : 0.7674\n","Batch 누적 : 700, Train Loss: 401.6833, Train Accuracy : 0.7674\n","validation 검증..........\n","Valid Loss: 0.3910, Valid Accuracy : 0.8590\n","Learning rate : 0.000010\n","model 'koelectra-adddata15.pth' save. the number of best_models: 15, model val acc : 0.859048******************\n","--------------------------------------------------------------------------------\n","epoch : 2-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 30.5708, Train Accuracy : 0.8950\n","Batch : 200, Train Loss: 58.9991, Train Accuracy : 0.9000\n","Batch : 300, Train Loss: 88.3709, Train Accuracy : 0.8982\n","Batch : 400, Train Loss: 115.9496, Train Accuracy : 0.9006\n","Batch : 500, Train Loss: 142.2699, Train Accuracy : 0.9029\n","Batch : 600, Train Loss: 168.4787, Train Accuracy : 0.9045\n","Batch : 700, Train Loss: 195.2601, Train Accuracy : 0.9052\n","Batch 누적 : 700, Train Loss: 195.2601, Train Accuracy : 0.9052\n","validation 검증..........\n","Valid Loss: 0.3828, Valid Accuracy : 0.8705\n","Learning rate : 0.000010\n","model 'koelectra-adddata16.pth' save. the number of best_models: 16, model val acc : 0.870500******************\n","--------------------------------------------------------------------------------\n","epoch : 3-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 16.6676, Train Accuracy : 0.9475\n","Batch : 200, Train Loss: 33.4076, Train Accuracy : 0.9489\n","Batch : 300, Train Loss: 51.7786, Train Accuracy : 0.9453\n","Batch : 400, Train Loss: 69.4506, Train Accuracy : 0.9445\n","Batch : 500, Train Loss: 85.4660, Train Accuracy : 0.9453\n","Batch : 600, Train Loss: 104.1362, Train Accuracy : 0.9451\n","Batch : 700, Train Loss: 124.8052, Train Accuracy : 0.9429\n","Batch 누적 : 700, Train Loss: 124.8052, Train Accuracy : 0.9429\n","validation 검증..........\n","Valid Loss: 0.4244, Valid Accuracy : 0.8685\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 4-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 11.6486, Train Accuracy : 0.9634\n","Batch : 200, Train Loss: 23.7258, Train Accuracy : 0.9627\n","Batch : 300, Train Loss: 35.3198, Train Accuracy : 0.9629\n","Batch : 400, Train Loss: 47.5797, Train Accuracy : 0.9624\n","Batch : 500, Train Loss: 58.9428, Train Accuracy : 0.9631\n","Batch : 600, Train Loss: 70.3655, Train Accuracy : 0.9629\n","Batch : 700, Train Loss: 83.1229, Train Accuracy : 0.9624\n","Batch 누적 : 700, Train Loss: 83.1229, Train Accuracy : 0.9624\n","validation 검증..........\n","Valid Loss: 0.4583, Valid Accuracy : 0.8753\n","Learning rate : 0.000010\n","model 'koelectra-adddata17.pth' save. the number of best_models: 17, model val acc : 0.875310******************\n","--------------------------------------------------------------------------------\n","epoch : 5-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 9.1999, Train Accuracy : 0.9722\n","Batch : 200, Train Loss: 17.1142, Train Accuracy : 0.9739\n","Batch : 300, Train Loss: 23.6032, Train Accuracy : 0.9756\n","Batch : 400, Train Loss: 31.0844, Train Accuracy : 0.9765\n","Batch : 500, Train Loss: 39.8273, Train Accuracy : 0.9754\n","Batch : 600, Train Loss: 48.1873, Train Accuracy : 0.9756\n","Batch : 700, Train Loss: 57.7882, Train Accuracy : 0.9745\n","Batch 누적 : 700, Train Loss: 57.7882, Train Accuracy : 0.9745\n","validation 검증..........\n","Valid Loss: 0.4975, Valid Accuracy : 0.8760\n","Learning rate : 0.000010\n","model 'koelectra-adddata18.pth' save. the number of best_models: 18, model val acc : 0.876024******************\n","--------------------------------------------------------------------------------\n","epoch : 6-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 5.6057, Train Accuracy : 0.9837\n","Batch : 200, Train Loss: 11.4822, Train Accuracy : 0.9830\n","Batch : 300, Train Loss: 16.9181, Train Accuracy : 0.9834\n","Batch : 400, Train Loss: 24.1006, Train Accuracy : 0.9826\n","Batch : 500, Train Loss: 29.6270, Train Accuracy : 0.9827\n","Batch : 600, Train Loss: 35.1956, Train Accuracy : 0.9826\n","Batch : 700, Train Loss: 41.7889, Train Accuracy : 0.9817\n","Batch 누적 : 700, Train Loss: 41.7889, Train Accuracy : 0.9817\n","validation 검증..........\n","Valid Loss: 0.5426, Valid Accuracy : 0.8735\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 7-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 4.2824, Train Accuracy : 0.9859\n","Batch : 200, Train Loss: 8.9271, Train Accuracy : 0.9858\n","Batch : 300, Train Loss: 14.6209, Train Accuracy : 0.9840\n","Batch : 400, Train Loss: 18.6728, Train Accuracy : 0.9851\n","Batch : 500, Train Loss: 24.1775, Train Accuracy : 0.9850\n","Batch : 600, Train Loss: 29.0284, Train Accuracy : 0.9848\n","Batch : 700, Train Loss: 33.1489, Train Accuracy : 0.9850\n","Batch 누적 : 700, Train Loss: 33.1489, Train Accuracy : 0.9850\n","validation 검증..........\n","Valid Loss: 0.6106, Valid Accuracy : 0.8712\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 8-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.6902, Train Accuracy : 0.9906\n","Batch : 200, Train Loss: 6.8648, Train Accuracy : 0.9905\n","Batch : 300, Train Loss: 10.2018, Train Accuracy : 0.9904\n","Batch : 400, Train Loss: 13.9305, Train Accuracy : 0.9902\n","Batch : 500, Train Loss: 17.3532, Train Accuracy : 0.9899\n","Batch : 600, Train Loss: 22.0100, Train Accuracy : 0.9893\n","Batch : 700, Train Loss: 25.5638, Train Accuracy : 0.9894\n","Batch 누적 : 700, Train Loss: 25.5638, Train Accuracy : 0.9894\n","validation 검증..........\n","Valid Loss: 0.6134, Valid Accuracy : 0.8714\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 9-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.0276, Train Accuracy : 0.9897\n","Batch : 200, Train Loss: 4.6609, Train Accuracy : 0.9919\n","Batch : 300, Train Loss: 7.7320, Train Accuracy : 0.9914\n","Batch : 400, Train Loss: 11.2513, Train Accuracy : 0.9911\n","Batch : 500, Train Loss: 14.4172, Train Accuracy : 0.9906\n","Batch : 600, Train Loss: 18.5401, Train Accuracy : 0.9895\n","Batch : 700, Train Loss: 22.0828, Train Accuracy : 0.9896\n","Batch 누적 : 700, Train Loss: 22.0828, Train Accuracy : 0.9896\n","validation 검증..........\n","Valid Loss: 0.6398, Valid Accuracy : 0.8735\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","4fold elapsed time : 1820.1239349842072\n","==============================5fold start==============================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["epoch : 0-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 110.4316, Train Accuracy : 0.3253\n","Batch : 200, Train Loss: 220.7977, Train Accuracy : 0.3311\n","Batch : 300, Train Loss: 331.0129, Train Accuracy : 0.3327\n","Batch : 400, Train Loss: 441.5261, Train Accuracy : 0.3348\n","Batch : 500, Train Loss: 551.9383, Train Accuracy : 0.3328\n","Batch : 600, Train Loss: 662.4597, Train Accuracy : 0.3314\n","Batch : 700, Train Loss: 772.8713, Train Accuracy : 0.3324\n","Batch 누적 : 700, Train Loss: 772.8713, Train Accuracy : 0.3324\n","validation 검증..........\n","Valid Loss: 1.1030, Valid Accuracy : 0.3342\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 1-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 103.6276, Train Accuracy : 0.4822\n","Batch : 200, Train Loss: 168.2963, Train Accuracy : 0.6234\n","Batch : 300, Train Loss: 222.7940, Train Accuracy : 0.6801\n","Batch : 400, Train Loss: 271.7140, Train Accuracy : 0.7148\n","Batch : 500, Train Loss: 316.3915, Train Accuracy : 0.7386\n","Batch : 600, Train Loss: 358.1478, Train Accuracy : 0.7563\n","Batch : 700, Train Loss: 398.6352, Train Accuracy : 0.7691\n","Batch 누적 : 700, Train Loss: 398.6352, Train Accuracy : 0.7691\n","validation 검증..........\n","Valid Loss: 0.3714, Valid Accuracy : 0.8674\n","Learning rate : 0.000010\n","model 'koelectra-adddata19.pth' save. the number of best_models: 19, model val acc : 0.867440******************\n","--------------------------------------------------------------------------------\n","epoch : 2-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 27.4340, Train Accuracy : 0.9087\n","Batch : 200, Train Loss: 56.6418, Train Accuracy : 0.9025\n","Batch : 300, Train Loss: 85.0161, Train Accuracy : 0.9026\n","Batch : 400, Train Loss: 113.7593, Train Accuracy : 0.9021\n","Batch : 500, Train Loss: 140.0808, Train Accuracy : 0.9029\n","Batch : 600, Train Loss: 167.4395, Train Accuracy : 0.9028\n","Batch : 700, Train Loss: 194.4979, Train Accuracy : 0.9030\n","Batch 누적 : 700, Train Loss: 194.4979, Train Accuracy : 0.9030\n","validation 검증..........\n","Valid Loss: 0.3611, Valid Accuracy : 0.8773\n","Learning rate : 0.000010\n","model 'koelectra-adddata20.pth' save. the number of best_models: 20, model val acc : 0.877286******************\n","--------------------------------------------------------------------------------\n","epoch : 3-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 16.9334, Train Accuracy : 0.9431\n","Batch : 200, Train Loss: 34.1838, Train Accuracy : 0.9442\n","Batch : 300, Train Loss: 50.7797, Train Accuracy : 0.9440\n","Batch : 400, Train Loss: 67.5808, Train Accuracy : 0.9441\n","Batch : 500, Train Loss: 84.9807, Train Accuracy : 0.9439\n","Batch : 600, Train Loss: 104.4056, Train Accuracy : 0.9431\n","Batch : 700, Train Loss: 122.7777, Train Accuracy : 0.9425\n","Batch 누적 : 700, Train Loss: 122.7777, Train Accuracy : 0.9425\n","validation 검증..........\n","Valid Loss: 0.4101, Valid Accuracy : 0.8796\n","Learning rate : 0.000010\n","model 'koelectra-adddata21.pth' save. the number of best_models: 21, model val acc : 0.879619******************\n","--------------------------------------------------------------------------------\n","epoch : 4-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 12.2098, Train Accuracy : 0.9569\n","Batch : 200, Train Loss: 23.8528, Train Accuracy : 0.9577\n","Batch : 300, Train Loss: 36.2844, Train Accuracy : 0.9584\n","Batch : 400, Train Loss: 48.8895, Train Accuracy : 0.9585\n","Batch : 500, Train Loss: 60.3700, Train Accuracy : 0.9595\n","Batch : 600, Train Loss: 70.8316, Train Accuracy : 0.9605\n","Batch : 700, Train Loss: 82.2257, Train Accuracy : 0.9610\n","Batch 누적 : 700, Train Loss: 82.2257, Train Accuracy : 0.9610\n","validation 검증..........\n","Valid Loss: 0.4474, Valid Accuracy : 0.8819\n","Learning rate : 0.000010\n","model 'koelectra-adddata22.pth' save. the number of best_models: 22, model val acc : 0.881929******************\n","--------------------------------------------------------------------------------\n","epoch : 5-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 9.4794, Train Accuracy : 0.9722\n","Batch : 200, Train Loss: 16.1632, Train Accuracy : 0.9755\n","Batch : 300, Train Loss: 24.8966, Train Accuracy : 0.9737\n","Batch : 400, Train Loss: 33.9543, Train Accuracy : 0.9736\n","Batch : 500, Train Loss: 42.4616, Train Accuracy : 0.9736\n","Batch : 600, Train Loss: 49.4120, Train Accuracy : 0.9746\n","Batch : 700, Train Loss: 57.9561, Train Accuracy : 0.9739\n","Batch 누적 : 700, Train Loss: 57.9561, Train Accuracy : 0.9739\n","validation 검증..........\n","Valid Loss: 0.4674, Valid Accuracy : 0.8842\n","Learning rate : 0.000010\n","model 'koelectra-adddata23.pth' save. the number of best_models: 23, model val acc : 0.884250******************\n","--------------------------------------------------------------------------------\n","epoch : 6-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 4.6622, Train Accuracy : 0.9869\n","Batch : 200, Train Loss: 10.4797, Train Accuracy : 0.9839\n","Batch : 300, Train Loss: 15.9602, Train Accuracy : 0.9835\n","Batch : 400, Train Loss: 21.0771, Train Accuracy : 0.9836\n","Batch : 500, Train Loss: 26.4875, Train Accuracy : 0.9836\n","Batch : 600, Train Loss: 30.7166, Train Accuracy : 0.9842\n","Batch : 700, Train Loss: 36.6922, Train Accuracy : 0.9836\n","Batch 누적 : 700, Train Loss: 36.6922, Train Accuracy : 0.9836\n","validation 검증..........\n","Valid Loss: 0.5286, Valid Accuracy : 0.8814\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 7-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.7639, Train Accuracy : 0.9887\n","Batch : 200, Train Loss: 7.0382, Train Accuracy : 0.9895\n","Batch : 300, Train Loss: 12.2911, Train Accuracy : 0.9881\n","Batch : 400, Train Loss: 16.2846, Train Accuracy : 0.9880\n","Batch : 500, Train Loss: 21.6650, Train Accuracy : 0.9869\n","Batch : 600, Train Loss: 26.5200, Train Accuracy : 0.9866\n","Batch : 700, Train Loss: 29.8705, Train Accuracy : 0.9870\n","Batch 누적 : 700, Train Loss: 29.8705, Train Accuracy : 0.9870\n","validation 검증..........\n","Valid Loss: 0.5576, Valid Accuracy : 0.8837\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 8-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 3.1562, Train Accuracy : 0.9909\n","Batch : 200, Train Loss: 6.8508, Train Accuracy : 0.9889\n","Batch : 300, Train Loss: 9.8775, Train Accuracy : 0.9893\n","Batch : 400, Train Loss: 13.3047, Train Accuracy : 0.9891\n","Batch : 500, Train Loss: 17.7071, Train Accuracy : 0.9887\n","Batch : 600, Train Loss: 22.8924, Train Accuracy : 0.9877\n","Batch : 700, Train Loss: 26.6428, Train Accuracy : 0.9877\n","Batch 누적 : 700, Train Loss: 26.6428, Train Accuracy : 0.9877\n","validation 검증..........\n","Valid Loss: 0.5495, Valid Accuracy : 0.8839\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","epoch : 9-----------------------------------------------------------------\n","train 학습..........\n","Batch : 100, Train Loss: 2.6622, Train Accuracy : 0.9916\n","Batch : 200, Train Loss: 5.9255, Train Accuracy : 0.9912\n","Batch : 300, Train Loss: 8.9731, Train Accuracy : 0.9913\n","Batch : 400, Train Loss: 12.2528, Train Accuracy : 0.9908\n","Batch : 500, Train Loss: 15.2109, Train Accuracy : 0.9909\n","Batch : 600, Train Loss: 18.3783, Train Accuracy : 0.9907\n","Batch : 700, Train Loss: 20.7404, Train Accuracy : 0.9906\n","Batch 누적 : 700, Train Loss: 20.7404, Train Accuracy : 0.9906\n","validation 검증..........\n","Valid Loss: 0.5981, Valid Accuracy : 0.8819\n","Learning rate : 0.000010\n","--------------------------------------------------------------------------------\n","5fold elapsed time : 1821.19642496109\n"]}]},{"cell_type":"code","source":["test_dataset = CustomDataset(clean_test,'test')\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","\n","preds = []\n","for idx, m in enumerate(best_models): \n","    print(f'{idx+1}/{len(best_models)}번째 모델 예측 진행중')\n","    bestm = m\n","    bestm.eval()\n","    answer = []\n","    with torch.no_grad():\n","        for input_ids_batch, attention_masks_batch in tqdm(test_loader):\n","            y_pred = bestm(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0].detach().cpu().numpy()\n","            answer.extend(y_pred.argmax(axis=1))\n","            \n","    preds.append(answer)"],"metadata":{"id":"g5284ePR_JjM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644604100335,"user_tz":-540,"elapsed":76752,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"a533766c-8121-4ccf-97c0-12b7c04a9cbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/6번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2/6번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["3/6번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4/6번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5/6번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6/6번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.17it/s]\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","np_pred = np.array(preds).T\n","\n","pred = []\n","for i in range(1666):\n","    cnt = Counter(np_pred[i])\n","    pred.append(cnt.most_common()[0][0])\n","    "],"metadata":{"id":"7ExszuwX_JhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_dict1 = {0:\"entailment\" , 1: \"contradiction\" , 2:\"neutral\"}\n","\n","sample_submission['label'] = [label_dict1[_] for _ in pred]"],"metadata":{"id":"XUFOFRdx_Jfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_submission"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"hLswucrYIJOq","executionInfo":{"status":"ok","timestamp":1644604345117,"user_tz":-540,"elapsed":7,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"669c60fa-59d5-46d4-d4c6-d1d5a55416f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-2a83fdc5-0c7d-4870-ae36-d5b40f0fe7e8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>contradiction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>entailment</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>contradiction</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>contradiction</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1661</th>\n","      <td>1661</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1662</th>\n","      <td>1662</td>\n","      <td>entailment</td>\n","    </tr>\n","    <tr>\n","      <th>1663</th>\n","      <td>1663</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1664</th>\n","      <td>1664</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1665</th>\n","      <td>1665</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1666 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a83fdc5-0c7d-4870-ae36-d5b40f0fe7e8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2a83fdc5-0c7d-4870-ae36-d5b40f0fe7e8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2a83fdc5-0c7d-4870-ae36-d5b40f0fe7e8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      index          label\n","0         0  contradiction\n","1         1        neutral\n","2         2     entailment\n","3         3  contradiction\n","4         4  contradiction\n","...     ...            ...\n","1661   1661        neutral\n","1662   1662     entailment\n","1663   1663        neutral\n","1664   1664        neutral\n","1665   1665        neutral\n","\n","[1666 rows x 2 columns]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["sample_submission.to_csv(suv + 'aaaaaaaaa.csv', index=False)"],"metadata":{"id":"xLDH9DAsGNPM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["suv + 'kc_roberta-large_3fold.csv'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Q99RNgWaGoeD","executionInfo":{"status":"ok","timestamp":1644588430452,"user_tz":-540,"elapsed":433,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"575dd7db-8c6d-4213-8b6b-14aa8fe9e81c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'data/kc_roberta-large_3fold.csv'"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"rZ6NRSy1IXk4","executionInfo":{"status":"ok","timestamp":1644588797992,"user_tz":-540,"elapsed":7,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"87bb1fc1-51b4-4500-dd73-9beb85d7c566"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/015GithubRepos/Dacon_sentence_classification'"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["for _ in np_pred[:50]:\n","    print(f'{_}\\t{Counter(_)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyrD537RIf2d","executionInfo":{"status":"ok","timestamp":1644604351623,"user_tz":-540,"elapsed":282,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"7b35dc13-4c03-4f01-f20d-e421376a7c76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[1 1 1 2 2 2]\tCounter({1: 3, 2: 3})\n","[2 2 2 0 0 0]\tCounter({2: 3, 0: 3})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[2 2 2 1 1 1]\tCounter({2: 3, 1: 3})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[0 0 0 2 2 2]\tCounter({0: 3, 2: 3})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[0 0 0 2 2 2]\tCounter({0: 3, 2: 3})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[0 0 0 2 2 2]\tCounter({0: 3, 2: 3})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[2 2 2 2 2 2]\tCounter({2: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n","[1 1 1 1 1 1]\tCounter({1: 6})\n","[0 0 0 0 0 0]\tCounter({0: 6})\n"]}]},{"cell_type":"code","source":["for _ in range(11, 11+len(best_models)):\n","    torch.save(best_models[_-11], f'roberta-large{_}.pth')"],"metadata":{"id":"RxDpbGMKIicD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.load()"],"metadata":{"id":"ZCP-mDEKJbWK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 불러와서 예측"],"metadata":{"id":"XO1m6KRXLvmg"}},{"cell_type":"code","source":["import time\n","\n","test_dataset = CustomDataset(clean_test,'test')\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","preds = []\n","for _ in range(13):\n","    start = time.time()\n","    print(f'{_+1}/13 번째 모델 예측 진행중')\n","    m = torch.load(f'roberta-large-adddata{_}.pth')\n","    m.eval()\n","    answer = []\n","    with torch.no_grad():\n","        for input_ids_batch, attention_masks_batch in tqdm(test_loader):\n","            y_pred = m(\n","                input_ids_batch.to(device),\n","                attention_mask=attention_masks_batch.to(device)\n","                )[0].detach().cpu().numpy()\n","            answer.extend(y_pred.argmax(axis=1))\n","            \n","    preds.append(answer)\n","    print(f'elapsed time : {time.time() - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Enwp4cacLxMN","executionInfo":{"status":"ok","timestamp":1644651856916,"user_tz":-540,"elapsed":256285,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"7b9d4056-70a4-4d1e-fb22-7bd29d572d79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 20.160715579986572\n","2/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 21.847057104110718\n","3/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 24.572529792785645\n","4/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 19.216731071472168\n","5/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 20.553385972976685\n","6/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 19.54999041557312\n","7/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 19.084368228912354\n","8/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 19.55402183532715\n","9/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.870598793029785\n","10/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.861972093582153\n","11/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.829195976257324\n","12/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 18.046534776687622\n","13/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.859816551208496\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","np_pred = np.array(preds).T\n","\n","pred = []\n","for i in range(1666):\n","    cnt = Counter(np_pred[i])\n","    pred.append(cnt.most_common()[0][0])"],"metadata":{"id":"eSok3frMPP7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_dict1 = {0:\"entailment\" , 1: \"contradiction\" , 2:\"neutral\"}\n","\n","sample_submission['label'] = [label_dict1[_] for _ in pred]"],"metadata":{"id":"qL55s3_kPZqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for _ in np_pred[:50]:\n","    print(f'{_}\\t{Counter(_).most_common()[0][0]}\\t{Counter(_)}')"],"metadata":{"id":"QZ-pq5nvPZoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_submission.to_csv(suv + 'roberta-large-adddata.csv', index=False)"],"metadata":{"id":"_6lQbSZMPZlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ycIyvPIHPux7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 불러와서 앙상블"],"metadata":{"id":"urqlyh0dkXlR"}},{"cell_type":"code","source":["def soft_max(x):\n","    \n","    max = np.max(x,axis=1,keepdims=True) #returns max of each row and keeps same dims\n","    e_x = np.exp(x - max) #subtracts each row with its max value\n","    sum = np.sum(e_x,axis=1,keepdims=True) #returns sum of each row and keeps same dims\n","    f_x = e_x / sum \n","    return f_x"],"metadata":{"id":"OGuwXT1_se0B","executionInfo":{"status":"ok","timestamp":1644682155458,"user_tz":-540,"elapsed":278,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","print(f'불러오는 model name : {modelname}')\n","test_dataset = CustomDataset(clean_test,'test', modelname)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n","sum_probs = np.zeros((test_dataset.dataset.shape[0], 3), dtype = 'f')\n","\n","for _ in range(13):\n","    # 모델 1개로 예측 ----------------------------------------------------------\n","    start = time.time()\n","    print(f'{_+1}/13 번째 모델 예측 진행중')\n","    m = torch.load(f'roberta-large-adddata{_}.pth')\n","    m.eval()\n","    probs = np.empty((0,3), float)\n","\n","    with torch.no_grad():\n","        for input_ids_batch, attention_masks_batch in tqdm(test_loader):\n","            y_pred = m(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0].detach().cpu().numpy()\n","            probs = np.vstack((probs, soft_max(np.array(y_pred))))  # 3가지 클래스에 대한 확률값. 행렬 shape : 사이즈 X 3\n","            \n","    sum_probs += probs  # 예측 끝나면 더해줌 ********************************\n","    print(f'elapsed time : {time.time() - start}')\n","    # 모델 1개로 예측 ----------------------------------------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfqtOkqnkY2W","executionInfo":{"status":"ok","timestamp":1644682846570,"user_tz":-540,"elapsed":247850,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"33b09800-b985-4467-de09-409344e03b68"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["불러오는 model name : klue/roberta-large\n","1/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 15.155702829360962\n","2/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.991841554641724\n","3/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.89419913291931\n","4/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.921390533447266\n","5/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.901498079299927\n","6/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.77363133430481\n","7/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.686158418655396\n","8/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 17.878915309906006\n","9/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 19.047866344451904\n","10/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 21.194138288497925\n","11/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 21.39119243621826\n","12/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 21.056869745254517\n","13/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:12<00:00,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 23.942049741744995\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["for _ in range(23):\n","    # 모델 1개로 예측 ----------------------------------------------------------\n","    start = time.time()\n","    print(f'{_+1}/23 번째 모델 예측 진행중')\n","    m = torch.load(f'koelectra-adddata{_}.pth')\n","    m.eval()\n","    probs = np.empty((0,3), float)\n","\n","    with torch.no_grad():\n","        for input_ids_batch, attention_masks_batch in tqdm(test_loader):\n","            y_pred = m(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0].detach().cpu().numpy()\n","            probs = np.vstack((probs, soft_max(np.array(y_pred))))  # 3가지 클래스에 대한 확률값 배치만큼 쌓기. 행렬 shape : 사이즈 X 3\n","            \n","    sum_probs += probs  # 모델 예측 끝나면 더해줌 ********************************\n","    print(f'elapsed time : {time.time() - start}')\n","    # 모델 1개로 예측 ----------------------------------------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNyXrjlFvDUB","executionInfo":{"status":"ok","timestamp":1644683106180,"user_tz":-540,"elapsed":191526,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"521ba9ad-0ec7-4622-9bce-d71a563d4dfc"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["1/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 7.340185642242432\n","2/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 7.902773141860962\n","3/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  5.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.583792448043823\n","4/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.964864015579224\n","5/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 7.811848163604736\n","6/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.005470037460327\n","7/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.252460956573486\n","8/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.193335056304932\n","9/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 7.675370454788208\n","10/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.700007677078247\n","11/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 7.560232400894165\n","12/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 9.878109216690063\n","13/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.3476722240448\n","14/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  5.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.220571279525757\n","15/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.693399667739868\n","16/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.267611980438232\n","17/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.438199520111084\n","18/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.641277313232422\n","19/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.357936382293701\n","20/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.37936520576477\n","21/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.022168397903442\n","22/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.532229900360107\n","23/13 번째 모델 예측 진행중\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:04<00:00,  6.00it/s]"]},{"output_type":"stream","name":"stdout","text":["elapsed time : 8.447734355926514\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["pred = sum_probs.argmax(axis=1)"],"metadata":{"id":"wq7xwvaip6sp","executionInfo":{"status":"ok","timestamp":1644683240007,"user_tz":-540,"elapsed":268,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["label_dict1 = {0:\"entailment\" , 1: \"contradiction\" , 2:\"neutral\"}\n","\n","sample_submission['label'] = [label_dict1[_] for _ in pred]"],"metadata":{"id":"H5Mw6slkwywB","executionInfo":{"status":"ok","timestamp":1644683315032,"user_tz":-540,"elapsed":256,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["sample_submission.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"6rfzx2dFw-o5","executionInfo":{"status":"ok","timestamp":1644683331212,"user_tz":-540,"elapsed":278,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}},"outputId":"c8cf3ece-dcc7-4129-d515-b6d1a57c1bac"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-15373414-2398-4b4e-937f-f32e6acdd3ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>contradiction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>entailment</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>entailment</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>contradiction</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>contradiction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15373414-2398-4b4e-937f-f32e6acdd3ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-15373414-2398-4b4e-937f-f32e6acdd3ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-15373414-2398-4b4e-937f-f32e6acdd3ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   index          label\n","0      0  contradiction\n","1      1     entailment\n","2      2     entailment\n","3      3  contradiction\n","4      4  contradiction"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["sample_submission.to_csv(suv + 'robertaNkoelectra_ensem.csv', index=False)"],"metadata":{"id":"GhF_VQcPwywC","executionInfo":{"status":"ok","timestamp":1644683335250,"user_tz":-540,"elapsed":280,"user":{"displayName":"KYEONGCHAN LEE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijlkBQ-RF-9M31bBoivZTgflWV0Gg6YRg4O7Mesw=s64","userId":"03106579917275952793"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"COZiYJgfxBKw"},"execution_count":null,"outputs":[]}]}